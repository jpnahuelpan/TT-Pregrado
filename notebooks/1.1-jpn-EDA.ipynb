{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ml = pd.read_csv(\"../data/processed/ML_Chile_2022-12-27.csv\")\n",
    "df_f = pd.read_csv(\"../data/processed/FalabellaAyuda_2022-12-27.csv\")\n",
    "# df_ml = df_ml[df_ml[\"sentiment\"] != \"others\"]\n",
    "# df_f = df_f[df_f[\"sentiment\"] != \"others\"]\n",
    "# df_r = pd.read_csv(\"../data/processed/RipleyChile_2022-12-27.csv\")\n",
    "# df_p = pd.read_csv(\"../data/processed/tiendas_paris_2022-12-27.csv\")\n",
    "df = {\n",
    "    \"ML\": df_ml,\n",
    "    \"Falabella\": df_f,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML\n",
      "Falabella\n"
     ]
    }
   ],
   "source": [
    "# eliminar nan\n",
    "for key, value in df.items():\n",
    "    print(key)\n",
    "    value.dropna(subset=[\"tweet_text\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'user_location', 'created_at', 'tweet_text',\n",
       "       '@usernames_in_tweet', 'hashtags_in_tweet', 'sentiment', 'score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha de inicio: 2022-12-22 14:17:28+00:00\n",
      "Fecha de finalización: 2022-12-27 15:31:58+00:00\n",
      "Fecha de inicio: 2022-12-18 02:57:50+00:00\n",
      "Fecha de finalización: 2022-12-27 14:31:29+00:00\n"
     ]
    }
   ],
   "source": [
    "# peridod en el que se encuentran los datos.\n",
    "def periodo(df):\n",
    "    # Encuentra la fecha de inicio (la primera fecha en el dataframe)\n",
    "    fecha_inicio = df['created_at'].min()\n",
    "\n",
    "    # Encuentra la fecha de finalización (la última fecha en el dataframe)\n",
    "    fecha_finalizacion = df['created_at'].max()\n",
    "\n",
    "    # Imprime la fecha de inicio y finalización\n",
    "    print(\"Fecha de inicio:\", fecha_inicio)\n",
    "    print(\"Fecha de finalización:\", fecha_finalizacion)\n",
    "periodo(df_f)\n",
    "periodo(df_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tienda</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>multimode</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>quantiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML</td>\n",
       "      <td>77</td>\n",
       "      <td>143.701299</td>\n",
       "      <td>76.886120</td>\n",
       "      <td>[122, 130, 236, 139, 113, 114, 152, 73]</td>\n",
       "      <td>280</td>\n",
       "      <td>12</td>\n",
       "      <td>[84.0, 139.0, 223.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Falabella</td>\n",
       "      <td>434</td>\n",
       "      <td>139.421659</td>\n",
       "      <td>75.698042</td>\n",
       "      <td>[113]</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>[79.0, 126.5, 208.25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tienda  count        mean        std  \\\n",
       "0         ML     77  143.701299  76.886120   \n",
       "1  Falabella    434  139.421659  75.698042   \n",
       "\n",
       "                                 multimode  max  min              quantiles  \n",
       "0  [122, 130, 236, 139, 113, 114, 152, 73]  280   12   [84.0, 139.0, 223.0]  \n",
       "1                                    [113]  275    1  [79.0, 126.5, 208.25]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# medición de la longitud de los microtextos.\n",
    "import statistics as stats\n",
    "resultado = {\n",
    "    \"tienda\": [],\n",
    "    \"count\": [],\n",
    "    \"mean\": [],\n",
    "    \"std\": [],\n",
    "    \"multimode\": [],\n",
    "    \"max\": [],\n",
    "    \"min\": [],\n",
    "    \"quantiles\": [],\n",
    "}\n",
    "text_length = []\n",
    "for key, value in df.items():\n",
    "    for row in value.iterrows():\n",
    "        text_length.append(row[1][3].__len__())\n",
    "    resultado[\"tienda\"].append(key)\n",
    "    resultado[\"count\"].append(text_length.__len__())\n",
    "    resultado[\"mean\"].append(stats.mean(text_length))\n",
    "    resultado[\"std\"].append(stats.stdev(text_length))\n",
    "    resultado[\"multimode\"].append(stats.multimode(text_length))\n",
    "    resultado[\"max\"].append(max(text_length))\n",
    "    resultado[\"min\"].append(min(text_length))\n",
    "    resultado[\"quantiles\"].append(stats.quantiles(text_length))\n",
    "    text_length = []\n",
    "df_resultado = pd.DataFrame(resultado)\n",
    "df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/unknownsystem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from collections import Counter\n",
    "\n",
    "def word_frequency(data):\n",
    "    addi = ['si', 'mas', 'aun']\n",
    "    # Descarga la lista de stop words del español\n",
    "    words0 = []\n",
    "    stop_words = nltk.corpus.stopwords.words(\"spanish\")\n",
    "    for i in addi:\n",
    "        stop_words.append(i)\n",
    "    # Inicializa un contador de palabras en cero\n",
    "    word_count = Counter()\n",
    "    \n",
    "    # Itera a través de cada cadena en la lista de datos\n",
    "    for text in data:\n",
    "        # Separa la cadena en una lista de palabras\n",
    "        words = text.split()\n",
    "        \n",
    "        # Elimina las stop words de la lista de palabras\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        for word in words:\n",
    "            words0.append(word)\n",
    "        \n",
    "        # Actualiza el contador de palabras con la lista de palabras filtrada\n",
    "    word_count.update(words0)\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller\n",
    "spell = Speller('es')\n",
    "texts = []\n",
    "resultado = {}\n",
    "for key, value in df.items():\n",
    "    for row in value.iterrows():\n",
    "        texts.append(spell(row[1][3]))\n",
    "    resultado[key] = word_frequency(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ML': {'necesito': 21, 'compra': 16, 'cuenta': 15, 'hoy': 14, 'ahora': 12},\n",
       " 'Falabella': {'compra': 86,\n",
       "  'necesito': 74,\n",
       "  'regalo': 63,\n",
       "  'producto': 62,\n",
       "  'pedido': 54}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = {}\n",
    "for key, value in resultado.items():\n",
    "    keys[key] = {}\n",
    "    for top in sorted(value, key=value.get, reverse=True)[:5]:\n",
    "        keys[key][top] = value[top]\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "traduccion = {\n",
    "    \"sadness\": \"tristeza\",\n",
    "    \"joy\": \"alegría\",\n",
    "    \"anger\": \"enojo\",\n",
    "    \"surprise\": \"sorpresa\",\n",
    "    \"disgust\": \"rechazo\",\n",
    "    \"Fear\": \"miedo\",\n",
    "    \"others\": \"otros\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mercado Libre & Falabella\n",
      "otros (49) & otros (212)\n",
      "enojo (16) & enojo (172)\n",
      "tristeza (11) & tristeza (39)\n",
      "alegría (1) & alegría (11)\n"
     ]
    }
   ],
   "source": [
    "# Analisis cuantitativo de los sentimientos.\n",
    "from itertools import zip_longest\n",
    "print(f\"Mercado Libre & Falabella\")\n",
    "def sentimiento(df1, df2):\n",
    "    count1 = dict(df1[\"sentiment\"].value_counts())\n",
    "    count2 = dict(df2[\"sentiment\"].value_counts())\n",
    "    for (key1, value1), (key2, value2) in zip_longest(count1.items(), count2.items(), fillvalue=(\"none\", \"none\")):\n",
    "        print(f\"{traduccion[key1]} ({value1}) & {traduccion[key2]} ({value2})\")\n",
    "\n",
    "sentimiento(df_ml, df_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mercado Libre & Falabella\n",
      "nan (74) & nan (414)\n",
      "['AlexMeyerFrankfurt', 'MercadoLibre', 'Cadem'] (1) & ['falabella'] (7)\n",
      "['canal', 'Twitter', 'Chile', 'EngagementRate', 'datos', 'análisis'] (1) & ['pésimoservicio'] (1)\n",
      "['ALANMAYERFRANKFURT'] (1) & ['Falabella'] (1)\n",
      "none (none) & ['nocumplepromesacomercial'] (1)\n",
      "none (none) & ['iquique'] (1)\n",
      "none (none) & ['sernac'] (1)\n",
      "none (none) & ['2036833842'] (1)\n",
      "none (none) & ['WhatsApp'] (1)\n",
      "none (none) & ['FalaferiaTeRoba'] (1)\n",
      "none (none) & ['Incendio', 'VinadelMar'] (1)\n",
      "none (none) & ['VINADELMAR', 'Incendiovinadelmar', 'Incendiovina'] (1)\n",
      "none (none) & ['malservicio', 'rechazofalabella', 'sernac', 'Navidad2022'] (1)\n",
      "none (none) & ['AyudaConCasos'] (1)\n",
      "none (none) & ['falabella', 'negligentes'] (1)\n"
     ]
    }
   ],
   "source": [
    "# Análisis de hashtags\n",
    "print(f\"Mercado Libre & Falabella\")\n",
    "def hashtags(df1, df2):\n",
    "    count1 = dict(df1[\"hashtags_in_tweet\"].value_counts(dropna=False))\n",
    "    count2 = dict(df2[\"hashtags_in_tweet\"].value_counts(dropna=False))\n",
    "    for (key1, value1), (key2, value2) in zip_longest(count1.items(), count2.items(), fillvalue=(\"none\", \"none\")):\n",
    "        print(f\"{key1} ({value1}) & {key2} ({value2})\")\n",
    "hashtags(df_ml, df_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de usuarios que publicaron n tweets & Mercado Libre & Falabella\n",
      "Usuarios que publicaron 1 tweets & 49 & 198\n",
      "Usuarios que publicaron 2 tweets & 11 & 53\n",
      "Usuarios que publicaron 3 tweets & 2 & 13\n",
      "Usuarios que publicaron 4 tweets & none & 4\n",
      "Usuarios que publicaron 5 tweets & none & 6\n",
      "Usuarios que publicaron 6 tweets & none & 5\n",
      "Usuarios que publicaron 7 tweets & none & 1\n",
      "Usuarios que publicaron 8 tweets & none & 1\n"
     ]
    }
   ],
   "source": [
    "# Analisis de usuarios. 'user_id', 'user_location'\n",
    "print(\"Número de usuarios que publicaron n tweets & Mercado Libre & Falabella\")\n",
    "def users(df1, df2):\n",
    "    vnr = {}\n",
    "    vnr[\"Mercado Libre\"] = df1['user_id'].value_counts()\n",
    "    vnr[\"Falabella\"] = df2['user_id'].value_counts()\n",
    "    max_v = {\n",
    "        \"Mercado Libre\": vnr[\"Mercado Libre\"].max(),\n",
    "        \"Falabella\": vnr[\"Falabella\"].max(),\n",
    "    }\n",
    "    count = {}\n",
    "    for tienda in vnr.keys():\n",
    "        count[tienda] = {}\n",
    "        for idx in range(1, max_v[tienda] + 1):\n",
    "            count[tienda][f\"Usuarios que publicaron {idx} tweets\"] = len(vnr[tienda][vnr[tienda] == idx].keys())\n",
    "    for (k1, v1), (k2, v2) in zip_longest(count[\"Mercado Libre\"].items(), count[\"Falabella\"].items(), fillvalue=(\"none\", \"none\")):\n",
    "        if k1 == k2 or k1 != \"none\":\n",
    "            print(f\"{k1} & {v1} & {v2}\")\n",
    "        else:\n",
    "            print(f\"{k2} & {v1} & {v2}\")\n",
    "\n",
    "\n",
    "\n",
    "users(df_ml, df_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mercado Libre & Falabella\n",
      "nan (35) & nan (206)\n",
      "Chile (8) & Chile (40)\n",
      "Santiago, Chile (7) & Santiago, Chile (34)\n",
      "oriundo de San Miguel  (3) & Santiago de Chile (17)\n",
      "chile (3) & Santiago (12)\n",
      "Santiago - Chile (2) & Santiago, Metropolitana de Santiago (6)\n",
      "Hogwarts  (2) & puente alto, la foresta (6)\n",
      "Villa Alemana, Chile (2) & ÜT: -33.447159,-70.863025 (5)\n",
      "Santiago  (2) & Valparaíso, Chile (5)\n",
      "anywhere (1) & Concepción, Chile (5)\n",
      "Chillán, Chile (1) & Maipú, Chile (3)\n",
      "Antofagasta, CL (1) & chile (3)\n",
      "Santiago (1) & Santiago,Chile (3)\n",
      "Libertador San Martin (1) & Santiago / Chile (3)\n",
      "chillan (1) & Concepcion, Chile (3)\n",
      "Lejos (1) & Rancagua , Chile (3)\n",
      "Maipú, Chile (1) & Las Condes, Chile (3)\n",
      "Metropolitana de Santiago, Chi (1) & Concepción (2)\n",
      "Coyhaique, Aysén del General C (1) & Talca (2)\n",
      "Timboctu  (1) & Viña del Mar (2)\n",
      "San Felipe, Chile (1) & Viña del Mar, Chile (2)\n",
      "SANTIAGO (1) & Asteroide B612 (2)\n",
      "none (none) & Paine, Chile (2)\n",
      "none (none) & Santiago / Puerto Montt (2)\n",
      "none (none) & Tel Aviv Israel/Ovalle Chile (2)\n",
      "none (none) & Iquique, Chile (2)\n",
      "none (none) & Los Angeles (2)\n",
      "none (none) & Chile, Elqui Valley El Hinojal (2)\n",
      "none (none) & Chilito pueh (2)\n",
      "none (none) & bakerStreet,221B England (2)\n",
      "none (none) & La Florida, Chile (2)\n",
      "none (none) & Bío-Bío, Chile (1)\n",
      "none (none) & Maihue (1)\n",
      "none (none) & Quilicura, Chile (1)\n",
      "none (none) & santiago de chile (1)\n",
      "none (none) & SCL (1)\n",
      "none (none) & Minas tirith, Gondor (1)\n",
      "none (none) & santiago, Chile (1)\n",
      "none (none) & República de Chile (1)\n",
      "none (none) & San Felipe, Chile (1)\n",
      "none (none) & Ovalle y Valparaiso,Chile (1)\n",
      "none (none) & bogota (1)\n",
      "none (none) & En algun lugar del Mundo (1)\n",
      "none (none) & Metropolitana de Santiago, Chi (1)\n",
      "none (none) & Wherever (1)\n",
      "none (none) & Puerto Montt, Chile (1)\n",
      "none (none) & Talagante, Chile (1)\n",
      "none (none) & Coquimbo, Chile (1)\n",
      "none (none) & Putaendo, Chile (1)\n",
      "none (none) & Algarve, Portugal (1)\n",
      "none (none) & usa (1)\n",
      "none (none) & Temuko (1)\n",
      "none (none) & Chile, Santiago de Chile (1)\n",
      "none (none) & Calera de Tango, Chile (1)\n",
      "none (none) & Quilpue (1)\n",
      "none (none) & Puerto Varas, Los Lagos (1)\n",
      "none (none) & Puerto Octay (1)\n",
      "none (none) & Lo Espejo, Chile (1)\n",
      "none (none) & Villa Alemana, Chile (1)\n",
      "none (none) & En el infinito y más allá.  (1)\n",
      "none (none) & Hijuelas, Chile (1)\n",
      "none (none) & Santiago, Chile  (1)\n",
      "none (none) & Stgo (1)\n",
      "none (none) & La Pintana (1)\n",
      "none (none) & Talagante (1)\n",
      "none (none) & San Carlos, Chile (1)\n",
      "none (none) & Talca, Chile (1)\n",
      "none (none) & Santiago / Algarrobo (1)\n",
      "none (none) & Rancagua (1)\n",
      "none (none) & Córdoba, Argentina (1)\n",
      "none (none) & Chillan, Chile (1)\n",
      "none (none) & Chile, Valparaíso, Viña y mas (1)\n",
      "none (none) & Peor es Nada  (1)\n",
      "none (none) & Entre II y VI región (1)\n",
      "none (none) & santiago  (1)\n",
      "none (none) & cl 🏳️‍🌈 (1)\n",
      "none (none) & De Talcahuano a Buenos Aires. (1)\n",
      "none (none) & Curicó (1)\n",
      "none (none) & Chile. (1)\n",
      "none (none) & En El Campo Che🇨🇱 (1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mercado Libre & Falabella\")\n",
    "def localizacion(df1, df2):\n",
    "    count1 = dict(df1[\"user_location\"].value_counts(dropna=False))\n",
    "    count2 = dict(df2[\"user_location\"].value_counts(dropna=False))\n",
    "    for (key1, value1), (key2, value2) in zip_longest(count1.items(), count2.items(), fillvalue=(\"none\", \"none\")):\n",
    "        print(f\"{key1} ({value1}) & {key2} ({value2})\")\n",
    "localizacion(df_ml, df_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e95f38e479709bf2e64305c06c60d84abc8c78a6dc11795e98ec1510042d1042"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
