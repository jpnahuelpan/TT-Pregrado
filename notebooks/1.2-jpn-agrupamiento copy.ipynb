{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Falabella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ml = pd.read_csv(\"../data/processed/FalabellaAyuda_2022-12-27.csv\")\n",
    "df_ml.dropna(subset=[\"tweet_text\"], inplace=True)\n",
    "df_ml = df_ml[df_ml[\"sentiment\"] != \"others\"]\n",
    "df_ml = df_ml.sample(n=100)\n",
    "# df_r = pd.read_csv(\"../data/processed/RipleyChile_2022-12-27.csv\")\n",
    "# df_p = pd.read_csv(\"../data/processed/tiendas_paris_2022-12-27.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_list(df):\n",
    "    texts = df[\"tweet_text\"]\n",
    "    data = []\n",
    "    for text in texts:\n",
    "        data.append(text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pytorch were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "tokenizer_espa침ol = BertTokenizer.from_pretrained(\"../pytorch/\", do_lower_case=False)\n",
    "model = BertModel.from_pretrained(\"../pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import Features\n",
    "inputs = df_to_list(df_ml)\n",
    "inputs = Features.bert_encoder(inputs, tokenizer_espa침ol)\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "data_ml = {\n",
    "        \"max_polling_std\": Features.std_normalization(Features.max_polling(last_hidden_states)),\n",
    "        \"max_polling_z_score\": Features.z_score_normalization(Features.max_polling(last_hidden_states)),\n",
    "        \"max_polling_max\": Features.min_max_normalization(Features.max_polling(last_hidden_states)),\n",
    "        \"mean_polling_std\": Features.std_normalization(Features.mean_polling(last_hidden_states)),\n",
    "        \"mean_polling_z_score\": Features.z_score_normalization(Features.mean_polling(last_hidden_states)),\n",
    "        \"mean_polling_max\": Features.min_max_normalization(Features.mean_polling(last_hidden_states)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indexs(list, value):\n",
    "    list_aux = list.copy()\n",
    "    output = []\n",
    "    while True:\n",
    "        try:\n",
    "            index = list_aux.index(value)\n",
    "            output.append(index)\n",
    "            list_aux[index] = None\n",
    "        except ValueError:\n",
    "            break\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agrupamiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[37, 0.546], [24, 0.176], [59, 0.493], [67, 0.236], [37, 0.269], [41, 0.254]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "agrupamiento = {}\n",
    "metric = []\n",
    "for i in range(100):\n",
    "    metrica = []\n",
    "    for key, value in data_ml.items():\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=4,\n",
    "            init=\"random\",\n",
    "            max_iter=100,\n",
    "            random_state=i,\n",
    "            n_init=1,\n",
    "        ).fit(value)\n",
    "        agrupamiento[key] = list(kmeans.labels_)\n",
    "        metrica.append(metrics.silhouette_score(\n",
    "            value, kmeans.labels_, metric=\"sqeuclidean\"))\n",
    "    metric.append(metrica)\n",
    "    #print(f\"{round(metrica[0], 3)} {round(metrica[1], 3)} {round(metrica[2], 3)} {round(metrica[3], 3)} {round(metrica[4], 3)} {round(metrica[5], 3)}\")\n",
    "rs = []\n",
    "for i in range(6):\n",
    "    list_aux = []\n",
    "    for metrica in metric:\n",
    "        list_aux.append(metrica[i])\n",
    "    max_ = max(list_aux)\n",
    "    index = list_aux.index(max_)\n",
    "    rs.append([index, round(max_, 3)])\n",
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs rsScore cluster 1 cluster 2 cluster 3 cluster 4\n",
      "37 & 0.546 & anger (2), sadness (1) & anger (2), joy (2) & anger (2), joy (1) & anger (71), sadness (16), joy (3)\n",
      "24 & 0.176 & anger (65), sadness (14), joy (2) & anger (2), joy (1) & anger (7), joy (3), sadness (2) & anger (3), sadness (1)\n",
      "59 & 0.493 & anger (27), sadness (3) & joy (1) & anger (12), sadness (4), joy (3) & anger (38), sadness (10), joy (2)\n",
      "67 & 0.236 & anger (12) & anger (56), sadness (14), joy (2) & anger (6), joy (2) & anger (3), sadness (3), joy (2)\n",
      "37 & 0.269 & anger (3), sadness (1) & anger (6), joy (1) & anger (7), sadness (4), joy (3) & anger (61), sadness (12), joy (2)\n",
      "41 & 0.254 & anger (3), joy (1), sadness (1) & anger (26), sadness (7), joy (4) & anger (3), joy (1) & anger (45), sadness (9)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for key, value in data_ml.items():\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=4,\n",
    "        init=\"random\",\n",
    "        max_iter=100,\n",
    "        random_state=rs[i][0],\n",
    "        n_init=1,\n",
    "    ).fit(value)\n",
    "    agrupamiento[key] = list(kmeans.labels_)\n",
    "    i += 1\n",
    "clusters = {}\n",
    "for key, value in agrupamiento.items():\n",
    "    clusters[key] = {\n",
    "    \"cluster0\": df_ml.iloc[find_indexs(agrupamiento[key], 0)],\n",
    "    \"cluster1\": df_ml.iloc[find_indexs(agrupamiento[key], 1)],\n",
    "    \"cluster2\": df_ml.iloc[find_indexs(agrupamiento[key], 2)],\n",
    "    \"cluster3\": df_ml.iloc[find_indexs(agrupamiento[key], 3)],\n",
    "}\n",
    "# preprocesado vs sentimiento.\n",
    "print(\"rs rsScore cluster 1 cluster 2 cluster 3 cluster 4\")\n",
    "i=0\n",
    "for key0, value0 in clusters.items():\n",
    "    data = []\n",
    "    for key1, value1 in value0.items():\n",
    "        sentiment = dict(value1[\"sentiment\"].value_counts())\n",
    "        sentiment_values = list(sentiment.values())\n",
    "        sentiment_labels = list(sentiment.keys())\n",
    "        sentiment = [f\"{label} ({value})\" for label, value in zip(sentiment_labels, sentiment_values)]\n",
    "        data.append(sentiment)\n",
    "    string = f\"{rs[i][0]} & {rs[i][1]} & {data[0]} & {data[1]} & {data[2]} & {data[3]}\"\n",
    "    string = string.replace('[', '')\n",
    "    string = string.replace(']', '')\n",
    "    string = string.replace(\"'\", \"\")\n",
    "    print(string)\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracci칩n de infrmaci칩n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo TCRE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no les contestes por privado', 'dejen de acosarme', 'sigo sin respuesta']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "corpus = []\n",
    "key_list = list(clusters.keys())\n",
    "for _, value0 in clusters[key_list[0]].items():\n",
    "    corpus.append(value0['tweet_text'].tolist())\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo = 0\n",
    "corpus0 = []\n",
    "cluster_result = []\n",
    "for text_list in corpus:\n",
    "    for text in text_list:\n",
    "        corpus0.append(text)\n",
    "        cluster_result.append(grupo)\n",
    "    grupo += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dejen', 'contestes', 'acosarme', 'privado', 'sigo', 'respuesta', 'servicio', 'pedido', 'rt', 'navidad', 'falabella', 'mas', 'regalo', 'ayuda', 'esperando', 'compra', 'hacen', 'mierda', 'van', 'aun', 'si', 'igual', 'problema', 'solo', 'dias', 'ustedes', 'producto', 'gracias', 'jojojo', 'dinero', 'cliente', 'muchas', 'dia', 'verguenza', 'estan', 'compre', 'ser', 'tiempo', 'acabo', 'hola', 'vez', 'excelente', 'dejaron', 'feliz', 'necesito', 'solucion', 'responder', 'espero', 'peor', 'responden', 'llegara', 'pesimo', 'devolucion', 'quiero', 'sinverguenzas', 'empresa', 'horrible', 'atencion', 'entregar', 'demoran', 'llego', 'mensaje', 'nadie', 'puras', 'tan', 'estafadores', 'dan', 'seria', 'hija', 'dicen', 'da', 'reembolso', 'datos', 'caso', 'algun', 'mismo', 'ojala', 'senores', 'siempre', 'reclamo', 'llega', 'puede', 'hice', 'ahora', 'cada', 'fecha', 'despacho', 'desean', 'arruinaron', 'ninos', 'corazon', 'solucionar', 'medio', 'devuelvan', 'alguna', 'tres', 'mal', 'atienden', 'compren', 'hoy'], ['verguenza', 'excelente', 'estafadores', 'dejaron', 'servicio', 'ayuda', 'rt', 'pedido', 'respuesta', 'hacen', 'mas', 'falabella', 'van', 'mierda', 'cliente', 'sigo', 'igual', 'gracias', 'si', 'pesimo', 'problema', 'navidad', 'dinero', 'ustedes', 'jojojo', 'dias', 'compra', 'regalo', 'aun', 'dejen', 'privado', 'contestes', 'acosarme', 'solo', 'muchas', 'estan', 'dia', 'quiero', 'compre', 'acabo', 'tiempo', 'ser', 'producto', 'esperando', 'solucion', 'responder', 'atienden', 'peor', 'feliz', 'puras', 'horrible', 'llegara', 'espero', 'hola', 'tan', 'mensaje', 'necesito', 'recomiendo', 'nadie', 'demoran', 'dicen', 'empresa', 'senores', 'sinverguenzas', 'llego', 'vez', 'cargo', 'atencion', 'seria', 'devolucion', 'algun', 'responden', 'mismo', 'reclamo', 'compren', 'alguna', 'da', 'entregar', 'arruinaron', 'desean', 'hice', 'caso', 'correcto', 'despacho', 'llega', 'corazon', 'ninos', 'dan', 'menos', 'ejecutivo', 'reembolsaron', 'comunicarme', 'llegue', 'siempre', 'solucionar', 'plata', 'tienda', 'ojo', 'ojala', 'manana'], ['mierda', 'jojojo', 'igual', 'acabo', 'gracias', 'muchas', 'servicio', 'rt', 'respuesta', 'pedido', 'mas', 'falabella', 'aun', 'dinero', 'ayuda', 'hacen', 'si', 'sigo', 'regalo', 'dias', 'van', 'navidad', 'problema', 'ustedes', 'sinverguenzas', 'estan', 'compra', 'dia', 'compre', 'privado', 'contestes', 'acosarme', 'dejen', 'verguenza', 'solo', 'cliente', 'empresa', 'peor', 'producto', 'tiempo', 'esperando', 'ser', 'llega', 'excelente', 'dejaron', 'espero', 'solucion', 'responder', 'hola', 'feliz', 'puras', 'llegara', 'dicen', 'hecho', 'pesimo', 'necesito', 'demoran', 'horrible', 'vez', 'cuenta', 'mensaje', 'tan', 'quiero', 'atencion', 'nadie', 'llego', 'estafadores', 'devolucion', 'ninos', 'seria', 'alguna', 'responden', 'puede', 'entregar', 'algun', 'senores', 'hija', 'mismo', 'da', 'espere', 'veces', 'hice', 'reclamo', 'despacho', 'desean', 'arruinaron', 'corazon', 'dan', 'puntos', 'ahora', 'atienden', 'compren', 'siempre', 'caso', 'solucionar', 'avalada', 'mientras', 'pagamos', 'agosto', 'siguen'], ['verguenza', 'mierda', 'excelente', 'pedido', 'privado', 'dejen', 'acosarme', 'contestes', 'jojojo', 'mas', 'falabella', 'sigo', 'igual', 'hacen', 'acabo', 'estafadores', 'navidad', 'van', 'si', 'regalo', 'aun', 'dinero', 'problema', 'compra', 'dias', 'ustedes', 'cliente', 'muchas', 'dejaron', 'solo', 'estan', 'gracias', 'dia', 'esperando', 'compre', 'producto', 'pesimo', 'ser', 'tiempo', 'sinverguenzas', 'peor', 'solucion', 'hola', 'feliz', 'responder', 'respuesta', 'empresa', 'quiero', 'espero', 'necesito', 'llegara', 'puras', 'horrible', 'vez', 'demoran', 'mensaje', 'tan', 'nadie', 'dicen', 'llego', 'atencion', 'devolucion', 'llega', 'responden', 'atienden', 'seria', 'senores', 'entregar', 'algun', 'da', 'mismo', 'recomiendo', 'alguna', 'reclamo', 'ninos', 'hice', 'dan', 'arruinaron', 'desean', 'caso', 'despacho', 'hija', 'corazon', 'puede', 'compren', 'hecho', 'siempre', 'ojala', 'solucionar', 'ahora', 'cargo', 'ayuda', 'tienda', 'cuenta', 'medio', 'ojo', 'plata', 'manana', 'datos', 'correcto']]\n"
     ]
    }
   ],
   "source": [
    "from src import Summarize\n",
    "results = Summarize.TCRE(corpus0, cluster_result, 1)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e95f38e479709bf2e64305c06c60d84abc8c78a6dc11795e98ec1510042d1042"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
