{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Falabella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ml = pd.read_csv(\"../data/processed/FalabellaAyuda_2022-12-27.csv\")\n",
    "df_ml.dropna(subset=[\"tweet_text\"], inplace=True)\n",
    "df_ml = df_ml[df_ml[\"sentiment\"] != \"others\"]\n",
    "df_ml = df_ml.sample(n=100)\n",
    "# df_r = pd.read_csv(\"../data/processed/RipleyChile_2022-12-27.csv\")\n",
    "# df_p = pd.read_csv(\"../data/processed/tiendas_paris_2022-12-27.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_list(df):\n",
    "    texts = df[\"tweet_text\"]\n",
    "    data = []\n",
    "    for text in texts:\n",
    "        data.append(text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pytorch were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "tokenizer_español = BertTokenizer.from_pretrained(\"../pytorch/\", do_lower_case=False)\n",
    "model = BertModel.from_pretrained(\"../pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import Features\n",
    "inputs = df_to_list(df_ml)\n",
    "inputs = Features.bert_encoder(inputs, tokenizer_español)\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "data_ml = {\n",
    "        \"max_polling_std\": Features.std_normalization(Features.max_polling(last_hidden_states)),\n",
    "        \"max_polling_z_score\": Features.z_score_normalization(Features.max_polling(last_hidden_states)),\n",
    "        \"max_polling_max\": Features.max_min_normalization(Features.max_polling(last_hidden_states)),\n",
    "        \"mean_polling_std\": Features.std_normalization(Features.mean_polling(last_hidden_states)),\n",
    "        \"mean_polling_z_score\": Features.z_score_normalization(Features.mean_polling(last_hidden_states)),\n",
    "        \"mean_polling_max\": Features.max_min_normalization(Features.mean_polling(last_hidden_states)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indexs(list, value):\n",
    "    list_aux = list.copy()\n",
    "    output = []\n",
    "    while True:\n",
    "        try:\n",
    "            index = list_aux.index(value)\n",
    "            output.append(index)\n",
    "            list_aux[index] = None\n",
    "        except ValueError:\n",
    "            break\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agrupamiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[26, 0.371], [27, 0.082], [18, 0.544], [79, 0.202], [89, 0.223], [32, 0.239]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "agrupamiento = {}\n",
    "metric = []\n",
    "for i in range(100):\n",
    "    metrica = []\n",
    "    for key, value in data_ml.items():\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=4,\n",
    "            init=\"random\",\n",
    "            max_iter=100,\n",
    "            random_state=i,\n",
    "            n_init=1,\n",
    "        ).fit(value)\n",
    "        agrupamiento[key] = list(kmeans.labels_)\n",
    "        metrica.append(metrics.silhouette_score(\n",
    "            value, kmeans.labels_, metric=\"sqeuclidean\"))\n",
    "    metric.append(metrica)\n",
    "    #print(f\"{round(metrica[0], 3)} {round(metrica[1], 3)} {round(metrica[2], 3)} {round(metrica[3], 3)} {round(metrica[4], 3)} {round(metrica[5], 3)}\")\n",
    "rs = []\n",
    "for i in range(6):\n",
    "    list_aux = []\n",
    "    for metrica in metric:\n",
    "        list_aux.append(metrica[i])\n",
    "    max_ = max(list_aux)\n",
    "    index = list_aux.index(max_)\n",
    "    rs.append([index, round(max_, 3)])\n",
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs rsScore cluster 1 cluster 2 cluster 3 cluster 4\n",
      "26 & 0.371 & anger (6), sadness (3), joy (1) & sadness (2) & anger (70), sadness (14), joy (2) & joy (1), sadness (1)\n",
      "27 & 0.082 & sadness (6), anger (3), joy (2) & anger (72), sadness (12), joy (2) & sadness (2) & anger (1)\n",
      "18 & 0.544 & anger (18), sadness (6), joy (2) & anger (31), sadness (10), joy (1) & joy (1), sadness (1) & anger (27), sadness (3)\n",
      "79 & 0.202 & anger (69), sadness (13), joy (2) & anger (5), sadness (4) & anger (2), joy (2) & sadness (3)\n",
      "89 & 0.223 & anger (6), sadness (5), joy (1) & anger (66), sadness (12), joy (1) & joy (2) & anger (4), sadness (3)\n",
      "32 & 0.239 & anger (3), sadness (1), joy (1) & anger (37), sadness (11) & anger (35), sadness (7), joy (3) & anger (1), sadness (1)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for key, value in data_ml.items():\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=4,\n",
    "        init=\"random\",\n",
    "        max_iter=100,\n",
    "        random_state=rs[i][0],\n",
    "        n_init=1,\n",
    "    ).fit(value)\n",
    "    agrupamiento[key] = list(kmeans.labels_)\n",
    "    i += 1\n",
    "clusters = {}\n",
    "for key, value in agrupamiento.items():\n",
    "    clusters[key] = {\n",
    "    \"cluster0\": df_ml.iloc[find_indexs(agrupamiento[key], 0)],\n",
    "    \"cluster1\": df_ml.iloc[find_indexs(agrupamiento[key], 1)],\n",
    "    \"cluster2\": df_ml.iloc[find_indexs(agrupamiento[key], 2)],\n",
    "    \"cluster3\": df_ml.iloc[find_indexs(agrupamiento[key], 3)],\n",
    "}\n",
    "# preprocesado vs sentimiento.\n",
    "print(\"rs rsScore cluster 1 cluster 2 cluster 3 cluster 4\")\n",
    "i=0\n",
    "for key0, value0 in clusters.items():\n",
    "    data = []\n",
    "    for key1, value1 in value0.items():\n",
    "        sentiment = dict(value1[\"sentiment\"].value_counts())\n",
    "        sentiment_values = list(sentiment.values())\n",
    "        sentiment_labels = list(sentiment.keys())\n",
    "        sentiment = [f\"{label} ({value})\" for label, value in zip(sentiment_labels, sentiment_values)]\n",
    "        data.append(sentiment)\n",
    "    string = f\"{rs[i][0]} & {rs[i][1]} & {data[0]} & {data[1]} & {data[2]} & {data[3]}\"\n",
    "    string = string.replace('[', '')\n",
    "    string = string.replace(']', '')\n",
    "    string = string.replace(\"'\", \"\")\n",
    "    print(string)\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[22, 0.514], [57, 0.085], [51, 0.548], [82, 0.147], [82, 0.127], [64, 0.243]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agrupamiento = {}\n",
    "metric = []\n",
    "for i in range(100):\n",
    "    metrica = []\n",
    "    for key, value in data_ml.items():\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=4,\n",
    "            init=\"k-means++\",\n",
    "            max_iter=100,\n",
    "            random_state=i,\n",
    "            n_init=1,\n",
    "        ).fit(value)\n",
    "        agrupamiento[key] = list(kmeans.labels_)\n",
    "        metrica.append(metrics.silhouette_score(\n",
    "            value, kmeans.labels_, metric=\"sqeuclidean\"))\n",
    "    metric.append(metrica)\n",
    "    #print(f\"{round(metrica[0], 3)} {round(metrica[1], 3)} {round(metrica[2], 3)} {round(metrica[3], 3)} {round(metrica[4], 3)} {round(metrica[5], 3)}\")\n",
    "rs = []\n",
    "for i in range(6):\n",
    "    list_aux = []\n",
    "    for metrica in metric:\n",
    "        list_aux.append(metrica[i])\n",
    "    max_ = max(list_aux)\n",
    "    index = list_aux.index(max_)\n",
    "    rs.append([index, round(max_, 3)])\n",
    "rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs rsScore cluster 1 cluster 2 cluster 3 cluster 4\n",
      "22 & 0.514 & anger (75), sadness (19), joy (3) & sadness (1) & anger (1) & joy (1)\n",
      "57 & 0.085 & sadness (2), anger (2), joy (1) & anger (71), sadness (16), joy (3) & anger (3), sadness (1) & sadness (1)\n",
      "51 & 0.548 & anger (34), sadness (10), joy (1) & joy (1), sadness (1) & anger (20), sadness (6), joy (2) & anger (22), sadness (3)\n",
      "82 & 0.147 & anger (24), sadness (6), joy (2) & anger (48), sadness (9), joy (1) & anger (1), joy (1), sadness (1) & sadness (4), anger (3)\n",
      "82 & 0.127 & anger (27), sadness (12), joy (2) & anger (48), sadness (7), joy (1) & anger (1), sadness (1) & joy (1)\n",
      "64 & 0.243 & anger (44), sadness (12) & anger (31), sadness (8), joy (3) & anger (1) & joy (1)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for key, value in data_ml.items():\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=4,\n",
    "        init=\"k-means++\",\n",
    "        max_iter=100,\n",
    "        random_state=rs[i][0],\n",
    "        n_init=1,\n",
    "    ).fit(value)\n",
    "    agrupamiento[key] = list(kmeans.labels_)\n",
    "    i += 1\n",
    "clusters = {}\n",
    "for key, value in agrupamiento.items():\n",
    "    clusters[key] = {\n",
    "    \"cluster0\": df_ml.iloc[find_indexs(agrupamiento[key], 0)],\n",
    "    \"cluster1\": df_ml.iloc[find_indexs(agrupamiento[key], 1)],\n",
    "    \"cluster2\": df_ml.iloc[find_indexs(agrupamiento[key], 2)],\n",
    "    \"cluster3\": df_ml.iloc[find_indexs(agrupamiento[key], 3)],\n",
    "}\n",
    "# preprocesado vs sentimiento.\n",
    "print(\"rs rsScore cluster 1 cluster 2 cluster 3 cluster 4\")\n",
    "i = 0\n",
    "for key0, value0 in clusters.items():\n",
    "    data = []\n",
    "    for key1, value1 in value0.items():\n",
    "        sentiment = dict(value1[\"sentiment\"].value_counts())\n",
    "        sentiment_values = list(sentiment.values())\n",
    "        sentiment_labels = list(sentiment.keys())\n",
    "        sentiment = [f\"{label} ({value})\" for label, value in zip(sentiment_labels, sentiment_values)]\n",
    "        data.append(sentiment)\n",
    "    string = f\"{rs[i][0]} & {rs[i][1]} & {data[0]} & {data[1]} & {data[2]} & {data[3]}\"\n",
    "    string = string.replace('[', '')\n",
    "    string = string.replace(']', '')\n",
    "    string = string.replace(\"'\", \"\")\n",
    "    print(string)\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuzzy c-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.212, 0.012, 0.448, 0.125, 0.143, 0.271]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fcmeans import FCM\n",
    "agrupamiento = {}\n",
    "metric = []\n",
    "\n",
    "rs = []\n",
    "for key, value in data_ml.items():\n",
    "    data = np.array(value)\n",
    "    fcm = FCM(n_clusters=4)\n",
    "    fcm.fit(data)\n",
    "    labels = fcm.predict(data)\n",
    "    grupos = fcm.soft_predict(data)\n",
    "    agrupamiento[key] = labels\n",
    "    rs.append(round(metrics.silhouette_score(\n",
    "        value, labels, metric=\"sqeuclidean\"), 3))\n",
    "    #print(f\"{round(metrica[0], 3)} {round(metrica[1], 3)} {round(metrica[2], 3)} {round(metrica[3], 3)} {round(metrica[4], 3)} {round(metrica[5], 3)}\")\n",
    "rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsScore cluster 1 cluster 2 cluster 3 cluster 4\n",
      "0.212 & anger (56), sadness (8) &  &  & anger (20), sadness (12), joy (4)\n",
      "0.012 & anger (2), sadness (1) & anger (26), sadness (8), joy (2) & anger (8), sadness (3), joy (1) & anger (40), sadness (8), joy (1)\n",
      "0.448 & anger (22), sadness (3) & anger (26), sadness (7), joy (1) & anger (21), sadness (7), joy (2) & anger (7), sadness (3), joy (1)\n",
      "0.125 &  & anger (42), sadness (7), joy (2) &  & anger (34), sadness (13), joy (2)\n",
      "0.143 &  &  & anger (27), sadness (12), joy (3) & anger (49), sadness (8), joy (1)\n",
      "0.271 & anger (41), sadness (12) &  & anger (35), sadness (8), joy (4) & \n"
     ]
    }
   ],
   "source": [
    "clusters = {}\n",
    "for key, value in agrupamiento.items():\n",
    "    clusters[key] = {\n",
    "    \"cluster0\": df_ml.iloc[find_indexs(list(agrupamiento[key]), 0)],\n",
    "    \"cluster1\": df_ml.iloc[find_indexs(list(agrupamiento[key]), 1)],\n",
    "    \"cluster2\": df_ml.iloc[find_indexs(list(agrupamiento[key]), 2)],\n",
    "    \"cluster3\": df_ml.iloc[find_indexs(list(agrupamiento[key]), 3)],\n",
    "\n",
    "}\n",
    "# preprocesado vs sentimiento.\n",
    "print(\"rsScore cluster 1 cluster 2 cluster 3 cluster 4\")\n",
    "i = 0\n",
    "for key0, value0 in clusters.items():\n",
    "    data = []\n",
    "    for key1, value1 in value0.items():\n",
    "        sentiment = dict(value1[\"sentiment\"].value_counts())\n",
    "        sentiment_values = list(sentiment.values())\n",
    "        sentiment_labels = list(sentiment.keys())\n",
    "        sentiment = [f\"{label} ({value})\" for label, value in zip(sentiment_labels, sentiment_values)]\n",
    "        data.append(sentiment)\n",
    "    string = f\"{rs[i]} & {data[0]} & {data[1]} & {data[2]} & {data[3]}\"\n",
    "    string = string.replace('[', '')\n",
    "    string = string.replace(']', '')\n",
    "    string = string.replace(\"'\", \"\")\n",
    "    print(string)\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eugenspace fuzzy c-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.017, 0.031, 0.452, 0.046, 0.023, 0.063]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=3, n_iter=2)\n",
    "\n",
    "agrupamiento = {}\n",
    "metric = []\n",
    "rs = []\n",
    "for key, value in data_ml.items():\n",
    "    data = svd.fit_transform(np.array(value))\n",
    "    fcm = FCM(n_clusters=4)\n",
    "    fcm.fit(data)\n",
    "    labels = fcm.predict(data)\n",
    "    grupos = fcm.soft_predict(data)\n",
    "    agrupamiento[key] = labels\n",
    "    rs.append(round(metrics.silhouette_score(\n",
    "        value, labels, metric=\"sqeuclidean\"), 3))\n",
    "    #print(f\"{round(metrica[0], 3)} {round(metrica[1], 3)} {round(metrica[2], 3)} {round(metrica[3], 3)} {round(metrica[4], 3)} {round(metrica[5], 3)}\")\n",
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsScore cluster 1 cluster 2 cluster 3 cluster 4\n",
      "0.017 & anger (39), sadness (5) & anger (9), sadness (6), joy (1) & joy (1), sadness (1) & anger (28), sadness (8), joy (2)\n",
      "0.031 & joy (1), sadness (1) & anger (27), sadness (8) & anger (15), sadness (9), joy (3) & anger (34), sadness (2)\n",
      "0.452 & anger (20), sadness (7), joy (2) & anger (20), sadness (3) & anger (29), sadness (7), joy (1) & anger (7), sadness (3), joy (1)\n",
      "0.046 & anger (22), sadness (5) & anger (17), sadness (7), joy (2) & anger (12), sadness (8), joy (2) & anger (25)\n",
      "0.023 & anger (18), sadness (8), joy (2) & anger (25), sadness (3) & anger (21), sadness (1) & anger (12), sadness (8), joy (2)\n",
      "0.063 & anger (26), sadness (4) & anger (17), sadness (3), joy (1) & anger (21), sadness (8) & anger (12), sadness (5), joy (3)\n"
     ]
    }
   ],
   "source": [
    "clusters = {}\n",
    "for key, value in agrupamiento.items():\n",
    "    clusters[key] = {\n",
    "    \"cluster0\": df_ml.iloc[find_indexs(list(agrupamiento[key]), 0)],\n",
    "    \"cluster1\": df_ml.iloc[find_indexs(list(agrupamiento[key]), 1)],\n",
    "    \"cluster2\": df_ml.iloc[find_indexs(list(agrupamiento[key]), 2)],\n",
    "    \"cluster3\": df_ml.iloc[find_indexs(list(agrupamiento[key]), 3)],\n",
    "\n",
    "}\n",
    "# preprocesado vs sentimiento.\n",
    "print(\"rsScore cluster 1 cluster 2 cluster 3 cluster 4\")\n",
    "i = 0\n",
    "for key0, value0 in clusters.items():\n",
    "    data = []\n",
    "    for key1, value1 in value0.items():\n",
    "        sentiment = dict(value1[\"sentiment\"].value_counts())\n",
    "        sentiment_values = list(sentiment.values())\n",
    "        sentiment_labels = list(sentiment.keys())\n",
    "        sentiment = [f\"{label} ({value})\" for label, value in zip(sentiment_labels, sentiment_values)]\n",
    "        data.append(sentiment)\n",
    "    string = f\"{rs[i]} & {data[0]} & {data[1]} & {data[2]} & {data[3]}\"\n",
    "    string = string.replace('[', '')\n",
    "    string = string.replace(']', '')\n",
    "    string = string.replace(\"'\", \"\")\n",
    "    print(string)\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de infrmación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import ast\n",
    "from config import OPENAI_API_KEY\n",
    "\n",
    "def ei(context, t):\n",
    "    response = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=f\"{context}:{t!r}\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=64,\n",
    "            top_p=1.0,\n",
    "            frequency_penalty=0.0,\n",
    "            presence_penalty=0.0\n",
    "        )\n",
    "    return response\n",
    "\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "context_e = \"\"\"\n",
    "        Extrae eventos especificando el tipo de evento,\n",
    "        tipos de evento:[Fecha, lugar, concecuencias],\n",
    "        el resultado retornalo como un diccionario de python, ejemplo:\n",
    "        {\n",
    "          \"tipo evento\": \"algo\",\n",
    "          \"lugar\": \"algo\",\n",
    "          \"consecuencias\": \"algo\",\n",
    "        }\n",
    "        es imperativo que respetes el formato de respuesta.\n",
    "    \"\"\"\n",
    "context_s =\"\"\"\n",
    "        Escribe un resumen de este texto:\n",
    "    \"\"\"\n",
    "context = [context_e, context_s]\n",
    "info_extraction = {}\n",
    "for key, value in clusters[\"max_polling_max\"].items():\n",
    "    texts = list(value[\"tweet_text\"])\n",
    "    t = \"\"\n",
    "    info_extraction[key] = {\n",
    "        \"resumen\": \"\",\n",
    "        \"eventos\": \"\",\n",
    "    }\n",
    "    for text in texts:\n",
    "        # info_extraction[key] = {\n",
    "        #     \"tipo evento\": [],\n",
    "        #     \"lugar\": [],\n",
    "        #     \"consecuencias\": [],\n",
    "        # }\n",
    "        t += str(text)\n",
    "    info_extraction[key][\"resumen\"] = ei(context_s, t).choices[0][\"text\"]\n",
    "    info_extraction[key][\"eventos\"] = ei(context_e, t).choices[0][\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cluster0': {'resumen': '\\n\\nEste texto muestra el descontento de un cliente por el retraso en la entrega de un regalo para navidad. El pedido debía llegar el 17 de diciembre, pero aún no se ha recibido. Al',\n",
       "  'eventos': '\\n\\nEvento:\\n{\\n  \"tipo evento\": \"Retraso en la entrega de una compra\",\\n  \"lugar\": \"Varios lugares (callcenter, tiendas, etc)\",\\n  \"consecuencias\": \"Dejar a'},\n",
       " 'cluster1': {'resumen': '\\n\\nEste texto se refiere a una mala experiencia de alguien que agradece la lección aprendida a pesar de la situación negativa. Esta experiencia ha enseñado a esa persona a valorar y agradecer',\n",
       "  'eventos': '\\n    Respuesta:\\n    {\\n      \"tipo evento\": \"mala experiencia\",\\n      \"lugar\": \"\",\\n      \"consecuencias\": \"\",\\n    }'},\n",
       " 'cluster2': {'resumen': '\\n\\nEste texto relata la experiencia de una persona al comprar por internet para navidad. Esta compra no se entregó a tiempo, lo que provocó que su hijo no recibiera su regalo a tiempo, y que el usu',\n",
       "  'eventos': '\\n\\nRespuesta:\\n{\\n  \"tipo evento\": \"No recibir regalo de navidad\",\\n  \"lugar\": \"En línea (Falabella)\",\\n  \"consecuencias\": \"Niño sin regalo de navidad\",\\n}'},\n",
       " 'cluster3': {'resumen': '\\n\\nEste texto relata la mala experiencia de varios usuarios al comprar productos en la empresa Falabella. Los problemas mencionados son la mala atención al cliente, el mal servicio post-venta, el retraso',\n",
       "  'eventos': ' \\n\\n{\\n  \"tipo evento\": \"Atencion al cliente\",\\n  \"lugar\": \"Falabella Mall Arauco Maipu\",\\n  \"consecuencias\": \"Horrible atencion al cliente, perdida de tiem'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e95f38e479709bf2e64305c06c60d84abc8c78a6dc11795e98ec1510042d1042"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
